<!DOCTYPE html>
<html>
<head>
  <!-- <title>FUSION: Frequency-guided Underwater Spatial Image Reconstruction</title> -->

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PB650VJH0M"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-PB650VJH0M');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./css/bulma.min.css">
  <link rel="stylesheet" href="./css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./css/bulma-slider.min.css">
  <link rel="stylesheet" href="./css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./css/index.css">
  <link rel="icon" href="./images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./js/fontawesome.all.min.js"></script>
  <script src="./js/bulma-carousel.min.js"></script>
  <script src="./js/bulma-slider.min.js"></script>
  <script src="./js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">TIDE: Two-Stage Inverse Degradation Estimation with Guided Prior
Disentanglement for Underwater Image Restoration</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Shravan&nbsp;Venkatraman<sup>*</sup><sup>1</sup>,</span>
            <span class="author-block">
              Rakesh&nbsp;Raj&nbsp;Madavan<sup>*</sup><sup>2</sup>,</span>
            <span class="author-block">
              Pavan Kumar S&nbsp;L&nbsp;K<sup>3</sup>
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Mohamed Bin Zayed University, UAE</span>
            <span class="author-block"><sup>2</sup>University of Amsterdam, The Netherlands</span>
            <span class="author-block"><sup>3</sup>University of Massachusetts, USA</span>
          </div>
          <h2 class="subtitle has-text-centered">
            <b style="color:tomato;">Submitted to WACV 2026</b><br><br>
          </h2>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link -->
              <span class="link-block">
                <a href="#" class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              
              <!-- Poster Link -->
              <span class="link-block">
                <a href="#" class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                    <i class="fas fa-images"></i>
                  </span>
                  <span>Poster</span>
                </a>
              </span>
              
              <!-- arXiv Link -->
              <span class="link-block">
                <a href="#" class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              
              <!-- Code Link -->
              <span class="link-block">
                <a href="https://github.com/shravan-18/TIDE-Experimentation" class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        TIDE, a two stage inverse degradation estimation framework that explicitly models degradation characteristics and applies targeted restoration through specialized prior decomposition.<br>
      </h2>
    </div>
  </div>
</section>

<br>
<center>
  <img src="./assets/Teaser_Cropped.pdf" alt="FUSION Architecture" style="width:1000px;height:200px;">
</center>
<br>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Underwater image restoration is essential for marine applications ranging from ecological monitoring to archaeological surveys, but effectively addressing the complex and spatially varying nature of underwater degradations remains a challenge. Existing methods typically apply uniform restoration strategies across the entire image, struggling to handle multiple co-occurring degradations that vary spatially and with water conditions. We introduce <b>TIDE</b>, a two stage inverse degradation estimation framework that explicitly models degradation characteristics and applies targeted restoration through specialized prior decomposition. Our approach disentangles the restoration process into multiple specialized hypotheses that are adaptively fused based on local degradation patterns, followed by a progressive refinement stage that corrects residual artifacts. Specifically, <b>TIDE</b> decomposes underwater degradations into four key factors, namely color distortion, haze, detail loss, and noise, and designs restoration experts specialized for each. By generating specialized restoration hypotheses, <b>TIDE</b> balances competing degradation factors and produces natural results even in highly degraded regions. Extensive experiments across both standard benchmarks and challenging turbid water conditions show that <b>TIDE</b> achieves competitive performance on reference based fidelity metrics while outperforming state of the art methods on non reference perceptual quality metrics, with strong improvements in color correction and contrast enhancement. Our code will be released upon acceptance. 
          </p>
          <br>
          <h2 class="title is-3"><center>Contributions</center></h2>
          <ul>
            <li>We present TIDE, a framework that addresses complex, spatially varying underwater degradations through a structured, multi-stage restoration process.</li>
            <li>We introduce a degradation-specific hypothesis generation and fusion strategy, which produces targeted corrections for distinct degradation types and combines them adaptively to handle heterogeneous distortions.</li>
            <li>We develop a residual-aware refinement mechanism that selectively enhances poorly restored regions, improving overall fidelity and perceptual quality without compromising well-recovered areas.</li>
          </ul>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<br>
<center>
  <img src="./assets/modelArch_cropped.pdf" alt="FUSION Architecture" style="width:900px;height:500px;">
</center>
<br>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"><b>TIDE: Method</b></h2>
        <div class="content has-text-justified">
          <p>
            We approach UIR via inverse degradation estimation and prior disentanglement. Instead of directly mapping degraded images to clean ones, we explicitly model degradations and apply targeted restoration. Different degradations require specialized treatment. Through prior disentanglement, we generate multiple hypotheses each addressing a specific degradation.  TIDE implements this in two stages: first, degradation-guided multi-hypothesis restoration combines specialized hypotheses; second, a refinement stage corrects residual degradations. 
          </p>
          <p>
            The <b>first</b> stage of TIDE performs inverse degradation mapping to identify the spatial distribution and severity of different degradation types, followed by specialized prior decomposition to generate targeted restoration hypotheses. Our <b>second</b> stage implements a progressive refinement approach that explicitly identifies and addresses these remaining artifacts through differential degradation analysis and expert-guided correction.
          </p>
        </div>
      </div>
    </div>
    <!--/ Method. -->
  </div>
</section>

<br>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Results: Qualitative on UIEB. -->
    <h2 class="title is-3 has-text-centered"><b>Qualitative Results: UIEB Dataset</b></h2>
    <br>
    <center>
      <img src="./assets/UIEB_Comparisons.pdf" alt="UIEB Qualitative Comparison" style="width:1200px;height:230px;">
    </center>
    <!-- <p class="has-text-centered is-size-6" style="margin-top:10px;">
      Visual comparison of FUSION against other state-of-the-art methods on the UIEB test set; note the restored natural colors and enhanced details.
    </p> -->
    <br>
    <!-- Results: Qualitative on EUVP. -->
    <h2 class="title is-3 has-text-centered"><b>Qualitative Results: EUVP Dataset</b></h2>
    <br>
    <center>
      <img src="./assets/EUVP_comparisons.pdf" alt="EUVP Qualitative Comparison" style="width:1200px;height:230px;">
    </center>
    <!-- <p class="has-text-centered is-size-6" style="margin-top:10px;">
      FUSION effectively recovers contrast and corrects color casts compared to competing approaches on EUVP.
    </p> -->
    <br>
    <h2 class="title is-3 has-text-centered"><b>Qualitative Results: SUIME Dataset</b></h2>
    <br>
    <center>
      <img src="./assets/SUIME_Comparisons.pdf" alt="SUIME Qualitative Comparison" style="width:1200px;height:230px;">
    </center>
    <!-- <p class="has-text-centered is-size-6" style="margin-top:10px;">
      Visual comparison of FUSION against other state-of-the-art methods on the UIEB test set; note the restored natural colors and enhanced details.
    </p> -->
    <br>
    <!-- Results: Ablation Study. -->
    <h2 class="title is-3 has-text-centered"><b>Ablation Study: Component Contributions</b></h2>
    <br>
    The table reports the effect of removing or altering individual components in terms of specialized decoders, loss functions, and supervision strategies. Results are evaluated on five standard datasets: EUVP, UIEB, SUIM-E, UIQS, and UCCS. Metrics include perceptual quality (LPIPS, â†“ is better), signal fidelity (PSNR, SSIM), and underwater image quality scores (UICM, UIConM).
    <br>

    <br>
    <center>
      <table border="1" cellspacing="0" cellpadding="10" style="border-collapse:collapse; text-align:center; width:100%; font-family:Arial, sans-serif; font-size:15px;">
      <thead>
        <tr style="background:#f0f0f0;">
          <th colspan="5">Config</th>
          <th colspan="3">EUVP</th>
          <th colspan="3">UIEB</th>
          <th colspan="3">SUIM-E</th>
          <th colspan="2">UIQS</th>
          <th colspan="2">UCCS</th>
        </tr>
        <tr style="background:#f9f9f9;">
          <th></th>
          <th>color</th>
          <th>contrast</th>
          <th>detail</th>
          <th>denoise</th>
          <th>LPIPS</th><th>PSNR</th><th>SSIM</th>
          <th>LPIPS</th><th>PSNR</th><th>SSIM</th>
          <th>LPIPS</th><th>PSNR</th><th>SSIM</th>
          <th>UICM</th><th>UIConM</th>
          <th>UICM</th><th>UIConM</th>
        </tr>
      </thead>
      <tbody>
        <!-- Decoder Types -->
        <tr>
          <td rowspan="7" style="writing-mode:vertical-rl; font-weight:bold;">Decoder Types</td>
          <td>Yes</td><td>No</td><td>No</td><td>No</td>
          <td>0.216</td><td>22.391</td><td>0.867</td>
          <td>0.158</td><td>22.809</td><td>0.890</td>
          <td>0.158</td><td>22.517</td><td>0.882</td>
          <td>13.451</td><td>0.847</td>
          <td>13.563</td><td>0.862</td>
        </tr>
        <tr>
          <td>Yes</td><td>Yes</td><td>No</td><td>No</td>
          <td>0.209</td><td>22.623</td><td>0.873</td>
          <td>0.205</td><td>23.333</td><td>0.901</td>
          <td>0.204</td><td>23.216</td><td>0.900</td>
          <td>13.642</td><td>0.894</td>
          <td>13.731</td><td>0.908</td>
        </tr>
        <tr>
          <td>Yes</td><td>No</td><td>Yes</td><td>No</td>
          <td>0.210</td><td>22.565</td><td>0.872</td>
          <td>0.207</td><td>23.239</td><td>0.899</td>
          <td>0.206</td><td>23.096</td><td>0.898</td>
          <td>13.598</td><td>0.885</td>
          <td>13.694</td><td>0.901</td>
        </tr>
        <tr>
          <td>Yes</td><td>No</td><td>No</td><td>Yes</td>
          <td>0.207</td><td>22.713</td><td>0.876</td>
          <td>0.203</td><td>23.210</td><td>0.899</td>
          <td>0.207</td><td>22.853</td><td>0.892</td>
          <td>13.683</td><td>0.909</td>
          <td>13.768</td><td>0.923</td>
        </tr>
        <tr>
          <td>Yes</td><td>Yes</td><td>Yes</td><td>No</td>
          <td>0.192</td><td>23.252</td><td>0.889</td>
          <td>0.203</td><td>23.494</td><td>0.904</td>
          <td>0.201</td><td>23.365</td><td>0.903</td>
          <td>14.087</td><td>1.012</td>
          <td>14.195</td><td>1.031</td>
        </tr>
        <tr>
          <td>Yes</td><td>Yes</td><td>No</td><td>Yes</td>
          <td>0.195</td><td>23.194</td><td>0.888</td>
          <td>0.201</td><td>23.488</td><td>0.902</td>
          <td>0.202</td><td>23.202</td><td>0.900</td>
          <td>14.024</td><td>0.991</td>
          <td>14.138</td><td>1.013</td>
        </tr>
        <tr>
          <td>Yes</td><td>No</td><td>Yes</td><td>Yes</td>
          <td>0.190</td><td>23.331</td><td>0.891</td>
          <td>0.200</td><td>23.484</td><td>0.903</td>
          <td>0.205</td><td>23.101</td><td>0.900</td>
          <td>14.145</td><td>1.024</td>
          <td>14.253</td><td>1.045</td>
        </tr>

        <!-- Loss -->
        <tr>
          <td rowspan="2" style="writing-mode:vertical-rl; font-weight:bold;">Loss</td>
          <td colspan="4">No Degradation Consistency</td>
          <td>0.354</td><td>19.841</td><td>0.792</td>
          <td>0.228</td><td>21.095</td><td>0.802</td>
          <td>0.252</td><td>21.626</td><td>0.792</td>
          <td>13.205</td><td>0.813</td>
          <td>13.458</td><td>0.826</td>
        </tr>
        <tr>
          <td colspan="4">No Diversity</td>
          <td>0.229</td><td>21.231</td><td>0.845</td>
          <td>0.170</td><td>22.701</td><td>0.886</td>
          <td>0.189</td><td>21.853</td><td>0.861</td>
          <td>13.894</td><td>0.962</td>
          <td>14.127</td><td>0.981</td>
        </tr>

        <!-- Supervision -->
        <tr>
          <td rowspan="4" style="writing-mode:vertical-rl; font-weight:bold;">Supervision</td>
          <td colspan="4">Direct Fusion</td>
          <td>0.200</td><td>22.973</td><td>0.882</td>
          <td>0.202</td><td>23.461</td><td>0.903</td>
          <td>0.221</td><td>23.042</td><td>0.897</td>
          <td>14.162</td><td>1.024</td>
          <td>14.297</td><td>1.047</td>
        </tr>
        <tr>
          <td colspan="4">No Degradation Maps</td>
          <td>0.223</td><td>22.022</td><td>0.859</td>
          <td>0.295</td><td>21.435</td><td>0.844</td>
          <td>0.255</td><td>23.259</td><td>0.902</td>
          <td>13.733</td><td>0.881</td>
          <td>13.946</td><td>0.902</td>
        </tr>
        <tr>
          <td colspan="4">Single Hypothesis</td>
          <td>0.202</td><td>22.868</td><td>0.880</td>
          <td>0.210</td><td>22.740</td><td>0.888</td>
          <td>0.210</td><td>22.494</td><td>0.884</td>
          <td>13.985</td><td>0.953</td>
          <td>14.104</td><td>0.968</td>
        </tr>
        <tr>
          <td colspan="4">No Refinement</td>
          <td>0.188</td><td>23.414</td><td>0.892</td>
          <td>0.202</td><td>23.547</td><td>0.904</td>
          <td>0.202</td><td>23.417</td><td>0.905</td>
          <td>14.294</td><td>1.065</td>
          <td>14.385</td><td>1.089</td>
        </tr>

        <!-- Full TIDE -->
        <tr style="writing-mode:vertical-rl; background:#d9d9d9; font-weight:bold;">
          <td colspan="5">Full TIDE</td>
          <td>0.159</td><td>29.469</td><td>0.906</td>
          <td>0.115</td><td>23.753</td><td>0.910</td>
          <td>0.119</td><td>25.987</td><td>0.906</td>
          <td>14.647</td><td>1.134</td>
          <td>14.729</td><td>1.107</td>
        </tr>
      </tbody>
    </table>

    </center>
  
    <p class="has-text-centered is-size-6" style="margin-top:10px;">
      Visual examples showing the impact of removing key modules: frequency attention, frequency branch, fusion, channel calibration, local attention, and global attention.
    </p>
    <br>
    <!-- Results: Efficiency Analysis. -->
    <h2 class="title is-3 has-text-centered"><b>Performance Analysis</b></h2>
    <br>
    <center>
      <img src="./assets/performance_analysis.pdf" alt="FPS vs Batch Size Trade-off" style="width:550px;height:400px;">
    </center>
    <p class="has-text-centered is-size-6" style="margin-top:10px;">
      TIDE achieves a fast rendering speed when using small image sizes like 128x128 and a relatively slow but favorable balance between FPS and Image sizes.
    </p>
    <br>
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{FUSION,
  author    = {Jaskaran Singh Walia and Shravan Venkatraman and Pavithra LK},
  title={FUSION: Frequency-guided Underwater Spatial Image recOnstructioN}, 
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  month     = {June},
  year      = {2025}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
